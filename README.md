# QuantMARLGA

**Multi-Agent Reinforcement Learning with Genetic Algorithm for Quantitative Trading**

RACE ë…¼ë¬¸ ê¸°ë°˜ GA+MARL í•˜ì´ë¸Œë¦¬ë“œ í•œêµ­ ì£¼ì‹ íŠ¸ë ˆì´ë”© ì‹œìŠ¤í…œ

---

## ğŸ“‹ í”„ë¡œì íŠ¸ ê°œìš”

### í•µì‹¬ ì•„ì´ë””ì–´
- **4ê°œ ì „ë¬¸í™” ì—ì´ì „íŠ¸**: Value, Quality, Portfolio, Hedging
- **ë³‘ë ¬ + ìœµí•© êµ¬ì¡°**: Value/Quality ë³‘ë ¬ â†’ Portfolio â†’ Hedging ìˆœì°¨
- **RACE ë°©ì‹ í•™ìŠµ**: EA Population (GA ì§„í™”) + MARL íŒ€ (RL í•™ìŠµ)
- **ì‹¤ì „ ë°ì´í„°**: í•œêµ­ ì£¼ì‹ ì‹œì¥ ì‹¤ì œ ë°ì´í„° (KOSPI ìƒìœ„ ì¢…ëª©)

### ì£¼ìš” íŠ¹ì§•
âœ… RACE ë…¼ë¬¸ ë°©ì‹ ì™„ì „ êµ¬í˜„ (EA vs MARL ë¶„ë¦¬)  
âœ… Shared Replay Buffer (ëª¨ë“  íŒ€ ê²½í—˜ ê³µìœ )  
âœ… Dynamic Injection (MARL â†’ EA worst êµì²´)  
âœ… ì‹¤ì œ ì‹œì¥ ë°ì´í„° íŒŒì´í”„ë¼ì¸  
âœ… ì°¨ë³„í™” ë³´ìƒ í•¨ìˆ˜ (ì—ì´ì „íŠ¸ë³„ ê¸°ì—¬ë„)  
âœ… 7ì¢… ì„±ê³¼ ì§€í‘œ (Sharpe, MDD, Calmar ë“±)  
âœ… **Rolling Window ìµœì í™”** (ë°ì´í„° í•œ ë²ˆë§Œ ë¡œë“œ, 99% ë‹¨ì¶•) ğŸš€  

---

## ğŸ—ï¸ ì‹œìŠ¤í…œ êµ¬ì¡°

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        EA Population (nê°œ)              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚ EA 0 â”‚ â”‚ EA 1 â”‚ ...  â”‚ EA n â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚     (GA ì§„í™”ë§Œ)                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â”œâ”€â”€â”€ Rollout â†’ Shared Buffer
            â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         MARL íŒ€ (1ê°œ)                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Value â†’ Quality â†’ Portfolio â†’    â”‚  â”‚
â”‚  â”‚                    Hedging       â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚     (RL í•™ìŠµë§Œ)                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â”œâ”€â”€â”€ Rollout â†’ Shared Buffer
            â”‚
            â””â”€â”€â”€ RL Update â† Shared Buffer
            â”‚
            â””â”€â”€â”€ Injection â†’ EA worst
```

---

## ğŸ“Š í•™ìŠµ ë£¨í”„

### Phase 1: Pure GA (ì„¸ëŒ€ 1-30)
1. Fitness í‰ê°€ (ë°±í…ŒìŠ¤íŠ¸ â†’ Sharpe Ratio)
2. Selection (Tournament + Elitism)
3. Crossover (Agent-level)
4. Mutation (Gaussian Noise)

### Phase 2: RACE Hybrid (ì„¸ëŒ€ 31-100)
1. **Fitness í‰ê°€** (EA Population)
2. **GA ì§„í™”** (EA Populationë§Œ)
3. **Rollout** (EA nê°œ + MARL 1ê°œ â†’ Shared Buffer)
4. **RL í•™ìŠµ** (MARL íŒ€ë§Œ, ëª¨ë“  ê²½í—˜ í™œìš©)
5. **Injection** (MARL â†’ EA worst êµì²´)
6. **ë‹¤ìŒ ì„¸ëŒ€ ì¤€ë¹„** (EA best â†’ MARL ë³µì œ)

---

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### í™˜ê²½ ì„¤ì •
```bash
# Conda í™˜ê²½ ìƒì„±
conda create -n quantagents python=3.10
conda activate quantagents

# íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install torch numpy pandas scipy
pip install FinanceDataReader pykrx OpenDartReader
pip install python-dotenv tqdm
```

### OpenDart API í‚¤ ì„¤ì •
```bash
# trading_marl_ga/.env íŒŒì¼ ìƒì„±
OPENDART_API_KEY=your_api_key_here
```

### ë°ì´í„° íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸
```bash
cd trading_marl_ga
python test_data_pipeline.py
```

### ë°±í…ŒìŠ¤íŠ¸ í™˜ê²½ í…ŒìŠ¤íŠ¸
```bash
python test_backtest_env.py
```

### GA Trainer í…ŒìŠ¤íŠ¸
```bash
python test_ga_trainer.py        # Pure GA
python test_race_hybrid.py       # RACE Hybrid
```

### ë²¤ì¹˜ë§ˆí¬ ë¹„êµ
```bash
python benchmarks.py              # Buy & Hold vs Equal Weight vs Random
python final_comparison.py        # GA-MARL vs Benchmarks
```

---

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
QuantMARLGA/
â”œâ”€â”€ trading_marl_ga/
â”‚   â”œâ”€â”€ agents/                    # ì—ì´ì „íŠ¸
â”‚   â”‚   â”œâ”€â”€ base_agent.py         # BaseAgent (Actor-Critic + GA)
â”‚   â”‚   â”œâ”€â”€ networks.py           # ì‹ ê²½ë§ (Actor, Critic)
â”‚   â”‚   â””â”€â”€ multi_agent_system.py # 4-Agent ì‹œìŠ¤í…œ
â”‚   â”‚
â”‚   â”œâ”€â”€ data/                      # ë°ì´í„° íŒŒì´í”„ë¼ì¸
â”‚   â”‚   â”œâ”€â”€ collectors/           # ë°ì´í„° ìˆ˜ì§‘ê¸°
â”‚   â”‚   â”‚   â”œâ”€â”€ price_collector.py
â”‚   â”‚   â”‚   â”œâ”€â”€ fundamental_collector.py
â”‚   â”‚   â”‚   â”œâ”€â”€ opendart_collector.py
â”‚   â”‚   â”‚   â””â”€â”€ financial_estimator.py
â”‚   â”‚   â””â”€â”€ market_data_manager.py # í†µí•© ê´€ë¦¬ì
â”‚   â”‚
â”‚   â”œâ”€â”€ environment/               # ë°±í…ŒìŠ¤íŠ¸ í™˜ê²½
â”‚   â”‚   â”œâ”€â”€ backtest_env.py       # ë§¤ë§¤ ì‹œë®¬ë ˆì´ì…˜
â”‚   â”‚   â””â”€â”€ reward_calculator_independent.py
â”‚   â”‚
â”‚   â”œâ”€â”€ evolution/                 # GA + RACE
â”‚   â”‚   â””â”€â”€ ga_trainer.py         # RACE ë°©ì‹ GA Trainer
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/                     # ìœ í‹¸ë¦¬í‹°
â”‚   â”‚   â”œâ”€â”€ observation.py        # ê´€ì¸¡ êµ¬ì„±
â”‚   â”‚   â”œâ”€â”€ replay_buffer.py      # Shared Replay Buffer
â”‚   â”‚   â””â”€â”€ metrics.py            # ì„±ê³¼ ì§€í‘œ
â”‚   â”‚
â”‚   â”œâ”€â”€ benchmarks.py              # ë²¤ì¹˜ë§ˆí¬ ì „ëµ
â”‚   â”œâ”€â”€ config.py                  # ì„¤ì •
â”‚   â””â”€â”€ test_*.py                  # í…ŒìŠ¤íŠ¸ íŒŒì¼ë“¤
â”‚
â”œâ”€â”€ 1.md - 5.md                    # í”„ë¡œì íŠ¸ ê³„íš ë¬¸ì„œ
â”œâ”€â”€ IMPLEMENTATION_STATUS.md       # êµ¬í˜„ í˜„í™©
â””â”€â”€ README.md                      # ì´ íŒŒì¼
```

---

## ğŸ“ˆ ì„±ê³¼ ì§€í‘œ

### êµ¬í˜„ëœ ì§€í‘œ (7ì¢…)
- **Total Return**: ì´ ìˆ˜ìµë¥ 
- **Sharpe Ratio**: ìœ„í—˜ ëŒ€ë¹„ ìˆ˜ìµë¥ 
- **Max Drawdown**: ìµœëŒ€ ë‚™í­
- **Win Rate**: ìŠ¹ë¥ 
- **Annualized Volatility**: ì—°ìœ¨í™” ë³€ë™ì„±
- **Calmar Ratio**: ìˆ˜ìµë¥  / MDD
- **Sortino Ratio**: í•˜ë°© ìœ„í—˜ ì¡°ì • ìˆ˜ìµë¥ 

### ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ (100ì¼, 2023ë…„)
| ì „ëµ | ìˆ˜ìµë¥  | ìƒ¤í”„ | MDD |
|------|--------|------|-----|
| Buy & Hold | 21.38% | 3.333 | -3.72% |
| KOSPI Index | 21.38% | 3.333 | -3.72% |
| Random Agent | 5.44% | 0.958 | -5.92% |

---

## ğŸ”¬ ì‹¤í—˜ ì„¤ì •

### ë°ì´í„°
- **ì¢…ëª©**: KOSPI ì‹œê°€ì´ì•¡ ìƒìœ„ 30ê°œ (10 â†’ 30 í™•ëŒ€)
- **ê¸°ê°„**: 2023ë…„ (ìµœì†Œ 200 ê±°ë˜ì¼ ë³´ì¥)
- **Lookback**: 60 ê±°ë˜ì¼ (ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚°ìš©)
- **ë¦¬ë°¸ëŸ°ì‹±**: ì£¼ê°„ (5ê±°ë˜ì¼ë§ˆë‹¤)

### í•˜ì´í¼íŒŒë¼ë¯¸í„° (ìµœì í™”ë¨ - 2025.11.24)
```python
# Environment
N_STOCKS = 30  # ë‹¤ì–‘ì„± ì¦ê°€
REBALANCE_PERIOD = 5  # ê±°ë˜ ë¹„ìš© ì ˆê°

# GA
POPULATION_SIZE = 10  # 30 â†’ 10 (íš¨ìœ¨ì„±)
N_GENERATIONS = 100
MUTATION_PROB = 0.9
MUTATION_SCALE_RATIO = 0.05  # ìƒëŒ€ì  ë…¸ì´ì¦ˆ
ELITE_FRACTION = 0.3  # ì•ˆì •ì„±

# RL
BATCH_SIZE = 256
BUFFER_CAPACITY = 10_000
MIN_BUFFER_FOR_RL = 256  # ì¦‰ì‹œ í•™ìŠµ
LEARNING_RATE_ACTOR = 3e-4
LEARNING_RATE_CRITIC = 1e-3
GAMMA = 0.99

# Hybrid
RL_UPDATES = 50  # ì„¸ëŒ€ë‹¹

# GPU (ìë™ ê°ì§€)
DEVICE = "cuda" if available else "cpu"
USE_AMP = True  # FP16 (Colab)
```

---

## âš¡ ì„±ëŠ¥ ìµœì í™”

### Rolling Window ë°ì´í„° ë¡œë”© (2025.11.24)
**ë¬¸ì œ**: ì„¸ëŒ€ë§ˆë‹¤ í™˜ê²½ ì¬ìƒì„± â†’ ë°ì´í„° ì¬ë¡œë“œ â†’ ì´ˆê¸°í™” ì‹œê°„ ë‚­ë¹„  
**í•´ê²°**: ì „ì²´ ê¸°ê°„ ë°ì´í„° í•œ ë²ˆë§Œ ë¡œë“œ, ê¸°ê°„ë³„ë¡œ ìŠ¬ë¼ì´ì‹±

| í•­ëª© | Before | After | ê°œì„  |
|------|--------|-------|------|
| ë°ì´í„° ë¡œë“œ | ì„¸ëŒ€ë‹¹ (100íšŒ) | **1íšŒ** | **100ë°°â†“** |
| ì´ˆê¸°í™” ì‹œê°„ | ì„¸ëŒ€ë‹¹ 10-20ì´ˆ | **ì „ì²´ 10-20ì´ˆ** | **99%â†“** |
| í•„í„°ë§ ì˜¤ë¥˜ | âŒ ë°œìƒ | âœ… **í•´ê²°** | ì•ˆì •ì„± |

**êµ¬í˜„**:
```python
# MarketDataManager: ì „ì²´ ê¸°ê°„ ë¡œë“œ
def initialize(self, start_date, end_date):
    self.all_dates = ...  # ì „ì²´ ê¸°ê°„ ë°ì´í„°
    
def set_backtest_period(self, start_date, end_date):
    self.common_dates = self.all_dates[mask]  # ìŠ¬ë¼ì´ì‹±ë§Œ

# GATrainer: í™˜ê²½ ì¬ì‚¬ìš©
self.env = BacktestEnv()  # í•œ ë²ˆë§Œ
for gen in range(n_generations):
    self.env.set_period(start_date, end_date)  # ê¸°ê°„ë§Œ ë³€ê²½
```

### GPU ê°€ì† (2025.11.24)
- **ëª…ì‹œì  Device ì „ì†¡**: ëª¨ë“  ë„¤íŠ¸ì›Œí¬/í…ì„œë¥¼ CUDAë¡œ
- **ì˜ˆìƒ ì„±ëŠ¥**: Colab A100ì—ì„œ 5-10ë°° ì†ë„ í–¥ìƒ
- **í˜¼í•© ì •ë°€ë„ (FP16)**: ë©”ëª¨ë¦¬ íš¨ìœ¨ ë° ì¶”ê°€ ê°€ì†

---

## ğŸ“ ë¬¸ì„œ

- **[IMPLEMENTATION_STATUS.md](IMPLEMENTATION_STATUS.md)**: êµ¬í˜„ í˜„í™© ë° ì§„í–‰ ìƒí™©
- **[2.md](2.md)**: 8ì‹œê°„ ì ì§„ì  êµ¬í˜„ ê³„íš
- **[3.md](3.md)**: ì‹œìŠ¤í…œ ì „ì²´ êµ¬ì¡° ì‹œê°í™”
- **[4.md](4.md)**: ë³´ìƒ í•¨ìˆ˜ ì„¤ê³„
- **[5.md](5.md)**: ë°ì´í„° íŒŒì´í”„ë¼ì¸ ì„¤ê³„

---

## ğŸ¯ í–¥í›„ ê³„íš

### ë‹¨ê¸° (1-2ì£¼)
- [ ] ì‹¤ì „ ê·œëª¨ í•™ìŠµ (Population 30, 100ì„¸ëŒ€)
- [ ] í•™ìŠµ ê³¡ì„  ì‹œê°í™”
- [ ] ìµœì¢… ì„±ê³¼ ë¶„ì„ ë¦¬í¬íŠ¸

### ì¤‘ê¸° (1ê°œì›”)
- [ ] ì¢…ëª© í™•ì¥ (10 â†’ 50ê°œ)
- [ ] Walk-Forward Validation
- [ ] í•˜ì´í¼íŒŒë¼ë¯¸í„° ìë™ íŠœë‹

### ì¥ê¸° (3ê°œì›”)
- [ ] Pre-training (Rule-Based Expert)
- [ ] ì‹¤ì‹œê°„ ë°ì´í„° ì—°ë™
- [ ] ìë™ ë§¤ë§¤ ì¸í„°í˜ì´ìŠ¤

---

## ğŸ“š ì°¸ê³  ë¬¸í—Œ

- **RACE ë…¼ë¬¸**: Cooperative Multi-Agent Reinforcement Learning with Genetic Algorithm
- **FinanceDataReader**: https://github.com/FinanceData/FinanceDataReader
- **pykrx**: https://github.com/sharebook-kr/pykrx
- **OpenDartReader**: https://github.com/FinanceData/OpenDartReader

---

## ğŸ“„ ë¼ì´ì„ ìŠ¤

MIT License

---

## ğŸ‘¥ ê¸°ì—¬

ì´ìŠˆ ë° PR í™˜ì˜í•©ë‹ˆë‹¤!

---

**ìƒì„±ì¼**: 2025-11-23  
**ìµœì¢… ì—…ë°ì´íŠ¸**: 2025-11-24 (GPU ìµœì í™”, í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹)  
**ì‘ì„±ì**: AI Assistant